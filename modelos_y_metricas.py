# -*- coding: utf-8 -*-
"""modelos y metricas

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DjlG3EBw_dKjv_I1dIB_B_CH8iO08JgX
"""

!pip install category_encoders
!pip install shap

import shap
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, confusion_matrix, balanced_accuracy_score
import xgboost as xgb
from sklearn.feature_selection import SelectFromModel
from plotnine import *
import plotnine
import sys
import category_encoders as ce

ruta = '/content/drive/MyDrive/Universidades/Maestria DM/Tesis Maestria/Python/'
df = pd.read_csv(ruta + 'dataF02.csv', delimiter = ';')

pd.options.display.max_columns = None
pd.options.display.max_rows = None
pd.set_option("display.max_colwidth", -1)
np.set_printoptions(threshold=sys.maxsize)


# arreglos finales

df['edad'].values[df['edad'].values >= 90] = 31
df['edad'].values[df['edad'].values <= 17] = 31



df.head()

from google.colab import drive
drive.mount('/content/drive')

# HIST AGE DISTRIBUTION

x = df.edad

plt.figure(figsize=(10,7))
plt.hist(x, color = '#7B89C1')
plt.title('EDAD DE LOS ESTUDIANTES', fontsize = 15)
plt.ylabel('CANTIDAD DE ESTUDIANTES', fontsize = 12)
plt.xlabel('EDAD', fontsize = 12)

"""**EXPLORATORY DATA ANALYSIS**"""

df.pivot_table(index='cant_eval_2021c2', aggfunc='size').plot(kind='bar', title = 'CLASS DISTRIBUTION', fontsize = 12, color = ['b','r'], figsize = (9,7), width = 0.5)

# % ABANDONO POBLACION

cant_0 = df.persona.where((df['cant_eval_m0']== 0)).notnull().sum()

cant_1 = df.persona.where((df['cant_eval_m0']== 1)).notnull().sum()

x = (cant_1/(cant_1+cant_0)).round(2)
y = (cant_0/(cant_1+cant_0)).round(2)
g = [x, y]

print('Cantidad de estudiantes: ', cant_1 + cant_0)
print('Abandonaron:     ', cant_1)
print('No Abandonaron:  ', cant_0)
print('% Abandono:      ', x)
print()

plt.figure(figsize = (9,6))
plt.title('% DE ABANDONO', fontsize = 15)
plt.pie(g, labels = g, colors = ['r','b'], radius = 1, textprops ={'fontsize': 15})
plt.show()

# _resultados_
# ABANDONO POR MAIL UNAHUR + institucional: 32% abandona vs 61% clase

cant_0 = df.persona.where((df['email'] < 3) & (df['cant_eval_m0']== 0)).notnull().sum()

cant_1 = df.persona.where((df['email'] < 3 ) & (df['cant_eval_m0']== 1)).notnull().sum()

x = (cant_1/(cant_1+cant_0)).round(2)
y = (cant_0/(cant_1+cant_0)).round(2)
g = [x, y]

print('Poblacion total: ', cant_1 + cant_0)
print('Abandonaron:     ', cant_1)
print('No Abandonaron:  ', cant_0)
print('% Abandono:      ', x)
print()

plt.figure(figsize = (9,6))
plt.title('% DE ABANDONO MAIL UNAHUR + institucionales', fontsize = 15)
plt.pie(g, labels = g, colors = ['r','b'], radius = 1, textprops ={'fontsize': 15})
plt.show()

# ABANDONO mails no institucionales  64% abandona vs 61% clase

cant_0 = df.persona.where((df['email'] > 2) & (df['cant_eval_m0']== 0)).notnull().sum()

cant_1 = df.persona.where((df['email'] > 2 ) & (df['cant_eval_m0']== 1)).notnull().sum()

x = (cant_1/(cant_1+cant_0)).round(2)
y = (cant_0/(cant_1+cant_0)).round(2)
g = [x, y]

print('Poblacion total: ', cant_1 + cant_0)
print('Abandonaron:     ', cant_1)
print('No Abandonaron:  ', cant_0)
print('% Abandono:      ', x)
print()

plt.figure(figsize = (9,6))
plt.title('% DE ABANDONO mails no institucionales', fontsize = 15)
plt.pie(g, labels = g, colors = ['r','b'], radius = 1, textprops ={'fontsize': 15})
plt.show()

# _resultados_
#ABANDONO POR sexo  0 F,1 M,2 O;  F 58% M 66%, O 56% (pero son 32 en total)

cant_0 = df.persona.where((df['sexo']== 2) & (df['cant_eval_m0']== 0)).notnull().sum()

cant_1 = df.persona.where((df['sexo']== 2) & (df['cant_eval_m0']== 1)).notnull().sum()

x = (cant_1/(cant_1+cant_0)).round(2)
y = (cant_0/(cant_1+cant_0)).round(2)
g = [x, y]

print('Poblacion total: ', cant_1 + cant_0)
print('Abandonaron:     ', cant_1)
print('No Abandonaron:  ', cant_0)
print('% Abandono:      ', x)
print()

plt.figure(figsize = (9,6))
plt.title('% DE ABANDONO Sexo', fontsize = 15)
plt.pie(g, labels = g, colors = ['r','b'], radius = 1, textprops ={'fontsize': 15})
plt.show()

#ABANDONO POR OUTLOOK: similar al the hotmail

cant_0 = df.persona.where((df['email']== 'outlook.com') & (df['cant_eval_2021c2']== 0)).notnull().sum()

cant_1 = df.persona.where((df['email']== 'outlook.com') & (df['cant_eval_2021c2']== 1)).notnull().sum()

x = (cant_1/(cant_1+cant_0)).round(2)
y = (cant_0/(cant_1+cant_0)).round(2)
g = [x, y]

print('Poblacion total: ', cant_1 + cant_0)
print('Abandonaron:     ', cant_1)
print('No Abandonaron:  ', cant_0)
print('% Abandono:      ', x)
print()

plt.figure(figsize = (9,6))
plt.title('% DE ABANDONO OUTLOOK', fontsize = 15)
plt.pie(g, labels = g, colors = ['r','b'], radius = 1, textprops ={'fontsize': 15})
plt.show()

plt.figure(figsize = (10,7))
x = ['gmail.com','outlook.com','hotmai.com','unahur.edu.ar']
y = [df.edad[df.email == 'gmail.com'].median(), df.edad[df.email == 'outlook.com'].median(), df.edad[df.email == 'hotmail.com'].median(), df.edad[df.email == 'unahur.edu.ar'].median()]
plt.bar(x,y, color = 'blue')
plt.title('EDAD MEDIA DE GENTE CON RESPECTIVO EMAIL')
plt.show()

#ABANDONO POR EDAD (MENORES DE 20)

cant_0 = df.persona.where((df['edad'] <= 20) & (df['cant_eval_m0']== 0)).notnull().sum()

cant_1 = df.persona.where((df['edad'] <= 20) & (df['cant_eval_m0']== 1)).notnull().sum()

x = (cant_1/(cant_1+cant_0)).round(2)
y = (cant_0/(cant_1+cant_0)).round(2)
g = [x, y]

print('Poblacion total: ', cant_1 + cant_0)
print('Abandonaron:     ', cant_1)
print('No Abandonaron:  ', cant_0)
print('% Abandono:      ', x)
print()

plt.figure(figsize = (7,4))
plt.title('% DE ABANDONO ESTUDIANTES MENORES DE 20', fontsize = 15)
plt.pie(g, labels = g, colors = ['r','b'], radius = 1, textprops ={'fontsize': 15})
plt.show()

# _resultados_  diferente abandono x edad
#ABANDONO POR EDAD (20 - 30)

cant_0 = df.persona.where((df['edad'] > 20) & (df['edad'] < 30) & (df['cant_eval_m0']== 0)).notnull().sum()

cant_1 = df.persona.where((df['edad'] > 20) & (df['edad'] < 30) & (df['cant_eval_m0']== 1)).notnull().sum()

x = (cant_1/(cant_1+cant_0)).round(2)
y = (cant_0/(cant_1+cant_0)).round(2)
g = [x, y]

print('Poblacion total: ', cant_1 + cant_0)
print('Abandonaron:     ', cant_1)
print('No Abandonaron:  ', cant_0)
print('% Abandono:      ', x)
print()

plt.figure(figsize = (9,6))
plt.title('% DE ABANDONO ESTUDIANTES ENTRE 20 Y 30', fontsize = 15)
plt.pie(g, labels = g, colors = ['r','b'], radius = 1, textprops ={'fontsize': 15})
plt.show()

#ABANDONO POR EDAD (MAYORES DE 30)

cant_0 = df.persona.where((df['edad'] > 30) & (df['cant_eval_m0']== 0)).notnull().sum()

cant_1 = df.persona.where((df['edad'] > 30) & (df['cant_eval_m0']== 1)).notnull().sum()

x = (cant_1/(cant_1+cant_0)).round(2)
y = (cant_0/(cant_1+cant_0)).round(2)
g = [x, y]

print('Poblacion total: ', cant_1 + cant_0)
print('Abandonaron:     ', cant_1)
print('No Abandonaron:  ', cant_0)
print('% Abandono:      ', x)
print()

plt.figure(figsize = (9,6))
plt.title('% DE ABANDONO ESTUDIANTES MAYORES DE 30', fontsize = 15)
plt.pie(g, labels = g, colors = ['grey','lightgrey'], radius = 1, textprops ={'fontsize': 15})
plt.show()

"""**CORRELACION DE ATRIBUTOS CON EL TARGET**"""

# _resultados_

df.corr()

df.head(3)

"""**ENCODING CATEGORICAL DATA**"""

# ONE HOT ENCODING: sexo, nacionalidad, email, estad civil, unido hecho, padre, madre, turno preferido, cobertura salud, tipo vivienda, vive con, celiaco, piso

for col in df:
    print(col, ': ', df[col].nunique())

"""**STANDARIZING NUMERICAL VARIABLES**"""

X = df.drop(['cant_eval_m0'], axis = 1)

X = X.set_index('persona')
y = df['cant_eval_m0']



# X = df_encoded.drop(['cant_eval_2021c2','fecha_actualizacion','fecha_nacimiento','fecha_ingreso_pais','censo_localidad','censo_cursada_localidad'], axis = 1)
#X = X.set_index('persona')
# y = df_encoded['cant_eval_2021c2']

# X_scaled = X.copy()

# from sklearn.preprocessing import StandardScaler

# scaler = StandardScaler()
# X_scaled[['edad','cant_eval_2020c1','cant_eval_2020c2','cant_eval_2021c1','meses_censo','censo_cantidad_hijos','censo_cantidad_familia',
#           'meses_ingreso_pais','address_driving_time(h)','address_cursada_driving_time(h)','address_distance(km)',
#           'address_cursada_distance(km)']] = scaler.fit_transform(X[[ 'edad','cant_eval_2020c1','cant_eval_2020c2',
#           'cant_eval_2021c1','meses_censo','censo_cantidad_hijos','censo_cantidad_familia',
#           'meses_ingreso_pais','address_driving_time(h)','address_cursada_driving_time(h)',
#           'address_distance(km)','address_cursada_distance(km)']])

# X_scaled.head()

df.to_csv('dataset.csv')
X.to_csv('X.csv')
y.to_csv('y.csv')

"""**TRAIN/TEST SPLIT**"""

def train_test(train_size):
  X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = train_size)
  return X_train, X_test, y_train, y_test

"""**MODEL METRICS**"""

def metrics(clf):
  y_score = clf.predict_proba(X_test)[:,1]
  fpr, tpr, thresholds = roc_curve(y_test, y_score)
  J = tpr-fpr
  index = np.argmax(J)
  thresholdOpt = thresholds[index]
  y_pred = (clf.predict_proba(X_test)[:,1] >= thresholdOpt).astype(bool)
  print('Confusion Matrix')
  print()
  print(confusion_matrix(y_test,y_pred))
  print('thresholdOpt', thresholdOpt)
  print('ROC-AUC:             ', roc_auc_score(y_test, y_score))
  print('Balanced Accuracy:   ', balanced_accuracy_score(y_test,y_pred))

"""**ROC CURVE + OPTIMAL TRESHOLD**"""

def roc(clf):
  y_score = clf.predict_proba(X_test)[:, 1]
  fpr, tpr, thresholds = roc_curve(y_test, y_score)
  df_fpr_tpr = pd.DataFrame({'FPR':fpr, 'TPR':tpr, 'Threshold':thresholds})
  J = tpr - fpr
  index = np.argmax(J)
  thresholdOpt = round(thresholds[index], ndigits = 4)
  fprOpt = round(fpr[index], ndigits = 4)
  tprOpt = round(tpr[index], ndigits = 4)
  print('Best Threshold: ', thresholdOpt)
  print()
  plotnine.options.figure_size = (8, 4.8)
  print((
    ggplot(data = df_fpr_tpr)+
    geom_point(aes(x = 'FPR',
                  y = 'TPR'),
              size = 0.4)+
    geom_point(aes(x = fprOpt,
                  y = tprOpt),
              color = '#981220',
              size = 4)+
    geom_line(aes(x = 'FPR',
                  y = 'TPR'))+
    geom_text(aes(x = fprOpt,
                  y = tprOpt),
              label = 'Optimal threshold \n for class: {}'.format(thresholdOpt),
              nudge_x = 0.14,
              nudge_y = -0.10,
              size = 10,
              fontstyle = 'italic')+
    labs(title = 'ROC Curve')+
    xlab('False Positive Rate (FPR)')+
    ylab('True Positive Rate (TPR)')+
    theme_minimal()
  ))

"""**FEATURE IMPORTANCE**"""

def fi(clf):

  import warnings
  warnings.filterwarnings("ignore")

  sort = clf.feature_importances_.argsort()[::-1]
  fi = clf.feature_importances_[sort]
  cols = X.columns[sort]

  fidf = pd.DataFrame()

  fidf['attribute'] = cols
  fidf['importance'] = fi

  fidf['importance'].loc[(fidf['attribute'].str.contains('address_driving_time(h)'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('address_driving_time(h)'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('address_driving_time(h)'))] = 'address_driving_time(h)'

  fidf['importance'].loc[(fidf['attribute'].str.contains('address_cursada_driving_time(h)'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('address_cursada_driving_time(h)'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('address_cursada_driving_time(h)'))] = 'address_cursada_driving_time(h)'

  fidf['importance'].loc[(fidf['attribute'].str.contains('address_distance(km)'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('address_distance(km)'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('address_distance(km)'))] = 'address_distance(km)'

  fidf['importance'].loc[(fidf['attribute'].str.contains('address_cursada_distance(km)'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('address_cursada_distance(km)'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('address_cursada_distance(km)'))] = 'address_cursada_distance(km)'


  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cursada_cp'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cursada_cp'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_cursada_cp'))] = 'censo_cursada_cp'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cp'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cp'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_cp'))] = 'censo_cp'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_turno_preferido'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_turno_preferido'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_turno_preferido'))] = 'censo_turno_preferido'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_estado_civil'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_estado_civil'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_estado_civil'))] = 'censo_estado_civil'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cursada_localidad_nombre'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cursada_localidad_nombre'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_cursada_localidad_nombre'))] = 'censo_cursada_localidad_nombre'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cobertura_salud'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cobertura_salud'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_cobertura_salud'))] = 'censo_cobertura_salud'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_localidad_nombre'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_localidad_nombre'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_localidad_nombre'))] = 'censo_localidad_nombre'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_altura'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_altura'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_altura'))] = 'censo_altura'

  fidf['importance'].loc[(fidf['attribute'].str.contains('email'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('email'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('email'))] = 'email'

  fidf['importance'].loc[(fidf['attribute'].str.contains('address'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('address'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('address'))] = 'address'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_unido_hecho'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_unido_hecho'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_unido_hecho'))] = 'censo_unido_hecho'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_barrio'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_barrio'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_barrio'))] = 'censo_barrio'

  fidf['importance'].loc[(fidf['attribute'].str.contains('address'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('address'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('address'))] = 'address'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_tipo_vivienda'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_tipo_vivienda'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_tipo_vivienda'))] = 'censo_tipo_vivienda'

  fidf['importance'].loc[(fidf['attribute'].str.contains('cant_hssemtrabajo'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('cant_hssemtrabajo'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('cant_hssemtrabajo'))] = 'cant_hssemtrabajo'

  fidf['importance'].loc[(fidf['attribute'].str.contains('cant_becas'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('cant_becas'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('cant_becas'))] = 'cant_becas'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_celiaco'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_celiaco'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_celiaco'))] = 'censo_celiaco'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_calle'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_calle'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_calle'))] = 'censo_calle'

  fidf['importance'].loc[(fidf['attribute'].str.contains('sexo'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('sexo'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('sexo'))] = 'sexo'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cursada_piso'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cursada_piso'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_cursada_piso'))] = 'censo_cursada_piso'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cursada_barrio'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cursada_barrio'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_cursada_barrio'))] = 'censo_cursada_barrio'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cursada_altura'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cursada_altura'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_cursada_altura'))] = 'censo_cursada_altura'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cursada_calle'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_cursada_calle'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_cursada_calle'))] = 'censo_cursada_calle'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_vive_con'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_vive_con'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_vive_con'))] = 'censo_vive_con'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_situacion_madre'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_situacion_madre'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_situacion_madre'))] = 'censo_situacion_madre'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_situacion_padre'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_situacion_padre'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_situacion_padre'))] = 'censo_situacion_padre'

  fidf['importance'].loc[(fidf['attribute'].str.contains('censo_piso'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('censo_piso'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('censo_piso'))] = 'censo_piso'

  fidf['importance'].loc[(fidf['attribute'].str.contains('nacionalidad'))] = fidf['importance'].loc[(fidf['attribute'].str.contains('nacionalidad'))].mean()
  fidf['attribute'].loc[(fidf['attribute'].str.contains('nacionalidad'))] = 'nacionalidad'

  fidf = fidf.drop_duplicates(subset=['attribute'])

  fidf = fidf.sort_values(by = 'importance', ascending=False)

  fidf = fidf[:20]

  fig = plt.figure()
  fig.set_size_inches(10, 12)
  plt.title('Mean Feature Importance')
  plt.xlabel('Feature Importance')
  plt.barh(fidf.attribute[::-1], fidf.importance[::-1], color = 'grey')

# if we were to predict all dropouts, we would get a 50% balanced accuracy

X_train, X_test, y_train, y_test = train_test(0.70)
y_pred = [1]*9354
y_pred = [1]*10076

print('Confusion Matrix')
print()
print(confusion_matrix(y_test,y_pred))
print()
print('Balanced Accuracy: ', balanced_accuracy_score(y_test,y_pred))

"""**DECISION TREE**"""

def build_tree():
  clf = DecisionTreeClassifier(criterion='entropy', max_depth = 9, min_samples_split=5,min_samples_leaf=3)
  clf.fit(X_train, y_train)
  return clf

X_train, X_test, y_train, y_test = train_test(0.7)
clf = build_tree()
fig = roc(clf)
metrics(clf)

fi(clf)

"""**LOGISTIC REGRESSION**"""

X_train, X_test, y_train, y_test = train_test(0.75)

# X_train = X_train[['meses_censo','cant_eval_2021c1','cant_eval_2020c2','cant_eval_2020c1','edad']]
# X_test = X_test[['meses_censo','cant_eval_2021c1','cant_eval_2020c2','cant_eval_2020c1','edad']]

clf = LogisticRegression(class_weight = 'balanced', max_iter = 1000)
clf = clf.fit(X_train, y_train)

roc(clf)
metrics(clf)

"""**SVM Model**"""

# best for accuracy C = 5, gamma = 0.1
X_train, X_test, y_train, y_test = train_test(0.75)

# sobre pesamos el 'no abandono' (39%) pesa 2. Abandono pesa 1.
pesos = 2 - y_train

from sklearn.svm import SVC
clf = SVC(probability = True, C = 5, gamma = 0.1,  kernel = "rbf")
clf.fit(X_train, y_train, sample_weight= pesos)

roc(clf)
metrics(clf)

# grid search SVM
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Split data into training and validation sets
# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)
X_train, X_val, y_train, y_val = train_test(0.75)

# Define grid of parameter values for Gamma and C Parameters
param_grid = {'gamma': [0.1, 0.5, 1.0], 'C': [1, 5, 10]}

# Define SVM model with RBF kernel
svm = SVC(kernel='rbf')

# Perform grid search with cross-validation
grid_search = GridSearchCV(svm, param_grid, cv=5)
grid_search.fit(X_train, y_train)

# Print best parameter values and accuracy on validation set
print("Best gamma value: ", grid_search.best_params_['gamma'])
print("Best C value: ", grid_search.best_params_['C'])
y_pred = grid_search.predict(X_val)
accuracy = accuracy_score(y_val, y_pred)
print("Validation accuracy: ", accuracy)

"""**RANDOM FOREST**"""

# from sklearn.ensemble import RandomForestClassifier

# clf = RandomForestClassifier(criterion = 'entropy', n_estimators = 500)
# clf.fit(X_train, y_train)
# roc(clf)
# metrics(clf)

"""**XGBOOST**"""

from sklearn.model_selection import RandomizedSearchCV

def xgb_ht():

  import xgboost as xgb

  params = {
      'max_depth': np.arange(1,11,2),
      'learning_rate': np.arange(0.01,1,0.1),
      'subsample': np.arange(0.5,1,0.1),
      'colsample_bytree': np.arange(0.4, 1.0, 0.1),
      'colsample_bylevel': np.arange(0.4, 1.0, 0.1),
      'gamma': np.arange(0.1,1,0.05),
      'reg_lambda': np.arange(1,9,2),
      'scale_pos_weight': np.arange(1,9,2),
      'n_estimators': np.arange(200,500,2)
    }

  xgb = xgb.XGBClassifier(objective = 'binary:logistic', seed=42, early_stopping_rounds = 10, eval_metric = 'auc')

  clf = RandomizedSearchCV( estimator = xgb,
                            param_distributions = params,
                            scoring='roc_auc',
                            verbose=False,
                            n_iter = 50)

  clf.fit(X_train,
          y_train,
          eval_set=[(X_test,y_test)],
          verbose=False)

  print(clf.best_params_)

def build_xgb():

  import xgboost as xgb

  clf_xgb = xgb.XGBClassifier(seed = 42,
                              objective = 'binary:logistic',
                              gamma=0.5,
                              learning_rate =0.2,
                              max_depth=9,
                              reg_lambda=5,
                              n_estimators = 256,
                              scale_pos_weight=3,
                              subsample=0.6,
                              colsample_bytree=0.7,
                              colsample_bylevel =0.6,
                              eval_metric='auc',
                              early_stopping_rounds=10)


  clf_xgb.fit(X_train,
              y_train,
              verbose=False,
              eval_set=[(X_test,y_test)])

  return clf_xgb

"""**HYPERPARAMETER TUNING XGB**"""

# xgb_ht()

"""**MODEL SUMMARY**"""

X_train, X_test, y_train, y_test = train_test(0.75)
xgb = build_xgb()
roc(xgb)
metrics(xgb)

"""**EXPLORING XGB FI**"""

from xgboost import plot_importance
plot_importance(xgb, max_num_features = 16, importance_type = 'weight')

plot_importance(xgb, max_num_features = 16, importance_type = 'cover')

plot_importance(xgb, max_num_features = 16, importance_type = 'gain')

fi(xgb)

"""**GRADIENT DESCENT ALGORITHM**"""

# gradient optimization
# bayesian optimization
# comparar los modelos (xgboost, arbol, regresion logistica, svm, random forest)

import random
def initialize(dim):
  b=random.random()
  theta=np.random.rand(dim)
  return b,theta

b,theta=initialize(3)
print("Bias: ",b, "Weights: ",theta)

"""**MULTIDIMENSIONAL PLOTS**"""

# import pandas as pd
# import plotly
# import plotly.graph_objs as go



# #Set marker properties
# markercolor = df_encoded['cant_eval_2021c2']

# #Make Plotly figure
# fig1 = go.Scatter3d(x=df_encoded['cant_eval_2021c1'],
#                     y=df_encoded['cant_eval_2020c2'],
#                     z=df_encoded['cant_eval_2020c1'],
#                     marker=dict(color=markercolor,
#                                 opacity=1,
#                                 reversescale=True,
#                                 colorscale='Blues',
#                                 size=5),
#                     line=dict (width=0.02),
#                     mode='markers')

# #Make Plot.ly Layout
# mylayout = go.Layout(scene=dict(xaxis=dict( title="curb-weight"),
#                                 yaxis=dict( title="horsepower"),
#                                 zaxis=dict(title="price")),)

# #Plot and save html
# plotly.offline.plot({"data": [fig1],
#                      "layout": mylayout},
#                      auto_open=True,
#                      filename=("4DPlot.html"))

def email_dropout():
  fig,axs = plt.subplots(2,2, figsize=(10,7))

  fig.suptitle('Abandono por Email', fontsize = 20)

  cant_0 = df.persona.where((df['cant_eval_2021c2']== 0)).notnull().sum()

  cant_1 = df.persona.where((df['cant_eval_2021c2']== 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[0,0].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[0,0].set_title('Abandono Poblacional', fontsize = 15)

  cant_0 = df.persona.where((df['email']== 'gmail.com') & (df['cant_eval_2021c2']== 0)).notnull().sum()

  cant_1 = df.persona.where((df['email']== 'gmail.com') & (df['cant_eval_2021c2']== 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[0,1].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[0,1].set_title('Abandono Gmail', fontsize = 15)

  cant_0 = df.persona.where((df['email']== 'hotmail.com') & (df['cant_eval_2021c2']== 0)).notnull().sum()

  cant_1 = df.persona.where((df['email']== 'hotmail.com') & (df['cant_eval_2021c2']== 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[1,0].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[1,0].set_title('Abandono Hotmail', fontsize = 15)

  cant_0 = df.persona.where((df['email']== 'unahur.edu.ar') & (df['cant_eval_2021c2']== 0)).notnull().sum()

  cant_1 = df.persona.where((df['email']== 'unahur.edu.ar') & (df['cant_eval_2021c2']== 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[1,1].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[1,1].set_title('Abandono Mail UNAHUR', fontsize = 15)

email_dropout()

def gender_dropout():
  fig,axs = plt.subplots(3, figsize=(10,7))

  fig.suptitle('Abandono por Sexo', fontsize = 20)

  cant_0 = df.persona.where((df['cant_eval_2021c2']== 0)).notnull().sum()

  cant_1 = df.persona.where((df['cant_eval_2021c2']== 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[0].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[0].set_title('Abandono Poblacional', fontsize = 15)

  cant_0 = df.persona.where((df['sexo'] =='M') & (df['cant_eval_2021c2']== 0)).notnull().sum()

  cant_1 = df.persona.where((df['sexo'] =='M') & (df['cant_eval_2021c2']== 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[1].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[1].set_title('Abandono Hombres', fontsize = 15)

  cant_0 = df.persona.where((df['sexo'] =='F') & (df['cant_eval_2021c2']== 0)).notnull().sum()

  cant_1 = df.persona.where((df['sexo'] =='F') & (df['cant_eval_2021c2']== 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[2].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[2].set_title('Abandono Mujeres', fontsize = 15)


gender_dropout()

def age_dropout():
  fig,axs = plt.subplots(2,2, figsize=(10,7))

  fig.suptitle('Abandono por Edad', fontsize = 20)

  cant_0 = df.persona.where((df['cant_eval_2021c2']== 0)).notnull().sum()

  cant_1 = df.persona.where((df['cant_eval_2021c2']== 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[0,0].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[0,0].set_title('Abandono Poblacional', fontsize = 15)

  cant_0 = df.persona.where((df['edad'] >= 18) & (df['edad'] <= 25) & (df['cant_eval_2021c2']== 0)).notnull().sum()

  cant_1 = df.persona.where((df['edad'] >= 18) & (df['edad'] <= 25) & (df['cant_eval_2021c2']== 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[0,1].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[0,1].set_title('Abandono 18-25', fontsize = 15)

  cant_0 = df.persona.where((df['edad'] > 25) & (df['edad'] < 40) & (df['cant_eval_2021c2']== 0)).notnull().sum()

  cant_1 = df.persona.where((df['edad'] > 25) & (df['edad'] < 40) & (df['cant_eval_2021c2']== 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[1,0].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[1,0].set_title('Abandono 25-40', fontsize = 15)

  cant_0 = df.persona.where((df['edad'] > 40) & (df['cant_eval_2021c2']== 0)).notnull().sum()

  cant_1 = df.persona.where((df['edad'] > 40) & (df['cant_eval_2021c2']== 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[1,1].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[1,1].set_title('Abandono 40+', fontsize = 15)

age_dropout()

df.persona.where((df['censo_turno_preferido'] == 1) | (df['censo_turno_preferido']== 4) | (df['censo_turno_preferido']== 5)).notnull().sum()

m1 = df.persona.where((df['sexo'] == 'M') & (df['cant_eval_2021c2']== 1)).notnull().sum()
m0 = df.persona.where((df['sexo'] == 'M') & (df['cant_eval_2021c2']== 0)).notnull().sum()
f1 = df.persona.where((df['sexo'] == 'F') & (df['cant_eval_2021c2']== 1)).notnull().sum()
f0 = df.persona.where((df['sexo'] == 'F') & (df['cant_eval_2021c2']== 0)).notnull().sum()

print('m0: ', m0)
print('m1: ', m1)
print('f0: ', f0)
print('f1: ', f1)

def edad():
  x = ['Poblacional','18-33','33-48','48-63','63-78','78+']

  y0 = df.persona.where((df['cant_eval_2021c2'] == 1)).notnull().sum() / df.persona.notnull().sum()
  y1 = df.persona.where((df['edad'] >= 18) & (df['edad'] < 33) & (df['cant_eval_2021c2'] == 1)).notnull().sum() / df.persona.where((df['edad'] >= 18) & (df['edad'] < 33)).notnull().sum()
  y2 = df.persona.where((df['edad'] >= 33) & (df['edad'] < 48) & (df['cant_eval_2021c2'] == 1)).notnull().sum() / df.persona.where((df['edad'] >= 33) & (df['edad'] < 48)).notnull().sum()
  y3 = df.persona.where((df['edad'] >= 48) & (df['edad'] < 63) & (df['cant_eval_2021c2'] == 1)).notnull().sum() / df.persona.where((df['edad'] >= 48) & (df['edad'] < 63)).notnull().sum()
  y4 = df.persona.where((df['edad'] >= 63) & (df['edad'] < 78) & (df['cant_eval_2021c2'] == 1)).notnull().sum() / df.persona.where((df['edad'] >= 63) & (df['edad'] < 78)).notnull().sum()
  y5 = df.persona.where((df['edad'] >= 78) & (df['edad'] < 99) & (df['cant_eval_2021c2'] == 1)).notnull().sum() / df.persona.where((df['edad'] >= 78) & (df['edad'] < 99)).notnull().sum()

  y = [y0.round(2),y1.round(2),y2.round(2),y3.round(2),y4.round(2),y5.round(2)]

  a = np.arange(len(x)) # the label locations
  width = 0.35 # the width of the bars

  fig, ax = plt.subplots(figsize = (10,7))

  ax.set_ylabel('% Abandono')
  ax.set_title('Edad')
  ax.set_xticks(a)
  ax.set_xticklabels(x)

  pps = ax.bar(a - width/2, y, width, label='%', color = 'grey')
  for p in pps:
    height = p.get_height()
    ax.annotate('{}'.format(height),
        xy=(p.get_x() + p.get_width() / 2, height),
        xytext=(0, 3), # 3 points vertical offset
        textcoords="offset points",
        ha='center', va='bottom')

  plt.show()

edad()

def hijos_dropout():

  df2 = df.copy()
  df2[df2['censo_cantidad_hijos'] >= 2] = 2

  fig,axs = plt.subplots(2,2, figsize=(10,7))

  fig.suptitle('Abandono por Cantidad de Hijos', fontsize = 20)

  cant_0 = df.persona.where((df['cant_eval_2021c2']== 0)).notnull().sum()

  cant_1 = df.persona.where((df['cant_eval_2021c2']== 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[0,0].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[0,0].set_title('Abandono Poblacional', fontsize = 15)

  cant_0 = df.persona.where((df['censo_cantidad_hijos'] == 0) & (df['cant_eval_2021c2'] == 0)).notnull().sum()

  cant_1 = df.persona.where((df['censo_cantidad_hijos'] == 0) & (df['cant_eval_2021c2'] == 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[0,1].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[0,1].set_title('Abandono 0 Hijos', fontsize = 15)

  cant_0 = df.persona.where((df['censo_cantidad_hijos'] == 1) & (df['cant_eval_2021c2'] == 0)).notnull().sum()

  cant_1 = df.persona.where((df['censo_cantidad_hijos'] == 1) & (df['cant_eval_2021c2'] == 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[1,0].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[1,0].set_title('Abandono 1 Hijo', fontsize = 15)

  cant_0 = df.persona.where((df2['censo_cantidad_hijos'] == 2) & (df['cant_eval_2021c2'] == 0)).notnull().sum()

  cant_1 = df.persona.where((df2['censo_cantidad_hijos'] == 2) & (df['cant_eval_2021c2'] == 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[1,1].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[1,1].set_title('Abandono 2+ Hijos', fontsize = 15)

hijos_dropout()

def hijos():

  x = ['Poblacional','0','1','2','3+']

  y0 = df.persona.where((df['cant_eval_2021c2'] == 1)).notnull().sum() / df.persona.notnull().sum()
  y5 = df.persona.where((df['censo_cantidad_hijos'] == 0) & (df['cant_eval_2021c2'] == 1)).notnull().sum() / df.persona[df['censo_cantidad_hijos'] == 0].notnull().sum()
  y1 = df.persona.where((df['censo_cantidad_hijos'] == 1) & (df['cant_eval_2021c2'] == 1)).notnull().sum() / df.persona[df['censo_cantidad_hijos'] == 1].notnull().sum()
  y2 = df.persona.where((df['censo_cantidad_hijos'] == 2) & (df['cant_eval_2021c2'] == 1)).notnull().sum() / df.persona[df['censo_cantidad_hijos'] == 2].notnull().sum()
  y3 = df.persona.where((df['censo_cantidad_hijos'] == 3) & (df['cant_eval_2021c2'] == 1)).notnull().sum() / df.persona[df['censo_cantidad_hijos'] == 3].notnull().sum()



  y = [y0.round(2),y5.round(2),y1.round(2),y2.round(2),y3.round(2)]

  a = np.arange(len(x)) # the label locations
  width = 0.35 # the width of the bars

  fig, ax = plt.subplots(figsize = (10,7))

  ax.set_ylabel('% Abandono')
  ax.set_title('Cantidad de Hijos')
  ax.set_xticks(a)
  ax.set_xticklabels(x)

  pps = ax.bar(a - width/2, y, width, label='%', color = 'grey')
  for p in pps:
    height = p.get_height()
    ax.annotate('{}'.format(height),
        xy=(p.get_x() + p.get_width() / 2, height),
        xytext=(0, 3), # 3 points vertical offset
        textcoords="offset points",
        ha='center', va='bottom')

  plt.show()

hijos()

def turno_dropout():

  import warnings
  warnings.filterwarnings("ignore")

  df2 = df.copy()

  df2['censo_turno_preferido'][(df2['censo_turno_preferido'] == 4) | (df2['censo_turno_preferido'] == 5)] = 1
  df2['censo_turno_preferido'][(df2['censo_turno_preferido'] == 6) | (df2['censo_turno_preferido'] == 7)] = 2
  df2['censo_turno_preferido'][(df2['censo_turno_preferido'] == 8) | (df2['censo_turno_preferido'] == 9)] = 3

  fig,axs = plt.subplots(2,2, figsize=(10,7))

  fig.suptitle('Abandono por Turno', fontsize = 20)

  cant_0 = df.persona.where((df['cant_eval_2021c2']== 0)).notnull().sum()

  cant_1 = df.persona.where((df['cant_eval_2021c2']== 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[0,0].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[0,0].set_title('Abandono Poblacional', fontsize = 15)

  cant_0 = df2.persona.where((df2['censo_turno_preferido'] == 1) & (df2['cant_eval_2021c2'] == 0)).notnull().sum()

  cant_1 = df2.persona.where((df2['censo_turno_preferido'] == 1) & (df2['cant_eval_2021c2'] == 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[0,1].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[0,1].set_title('Abandono Turno AM', fontsize = 15)

  cant_0 = df2.persona.where((df2['censo_turno_preferido'] == 2) & (df2['cant_eval_2021c2'] == 0)).notnull().sum()

  cant_1 = df2.persona.where((df2['censo_turno_preferido'] == 2) & (df2['cant_eval_2021c2'] == 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[1,0].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[1,0].set_title('Abandono Turno Tarde', fontsize = 15)

  cant_0 = df2.persona.where((df2['censo_turno_preferido'] == 3) & (df2['cant_eval_2021c2'] == 0)).notnull().sum()
  cant_1 = df2.persona.where((df2['censo_turno_preferido'] == 3) & (df2['cant_eval_2021c2'] == 1)).notnull().sum()

  x = (cant_1/(cant_1+cant_0)).round(2)
  y = (cant_0/(cant_1+cant_0)).round(2)
  g = [x, y]

  axs[1,1].pie(g, labels = g, colors =['grey','lightgrey'] )
  axs[1,1].set_title('Abandono Turno Noche', fontsize = 15)

turno_dropout()

df['censo_turno_preferido'][(df['censo_turno_preferido'] == 4) | (df['censo_turno_preferido'] == 5)] = 1
  df['censo_turno_preferido'][(df['censo_turno_preferido'] == 6) | (df['censo_turno_preferido'] == 7)] = 2
  df['censo_turno_preferido'][(df['censo_turno_preferido'] == 8) | (df['censo_turno_preferido'] == 9)] = 3

  df.censo_turno_preferido.value_counts()

"""**EXPLORING SHAP LIBRARY (INTERPRETABLE MACHINE LEARNING)**"""

df = df.set_index('persona')

import shap

explainer = shap.TreeExplainer(xgb, data = X_test, model_output='probability')
shap_values = explainer.shap_values(X_test)

X_test_2 = X_test.copy()
X_test_2['dropout_proba'] = xgb.predict_proba(X_test)[:,1].round(2)
output = X_test_2[['dropout_proba']].loc[X_test_2.dropout_proba >= .90]
output['apellido'] = df['apellido'].loc[list(output.index.values)]
output.sort_values(by='dropout_proba',ascending = False).head(10)

#Global importance on predictions
fig = plt.figure()
shap.summary_plot(shap_values, X_test, show = False, plot_type = 'violin')
plt.gcf().set_size_inches(15,7)
plt.show()

def force_plot(i):
  shap.initjs()
  p = shap.force_plot(explainer.expected_value, shap_values[list(X_test.index.values).index(i)], features=X_test.loc[i], feature_names=X_test.columns)
  return p

force_plot(18787)

import pickle
filename = 'xgb_model.sav'
pickle.dump(xgb, open(filename, 'wb'))